{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGCNN ([helped](https://github.com/ang3loliveira/behavioral_malware_detection_dgcnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norn_adj(X, input_dim_1):\n",
    "    \n",
    "    A = torch.zeros((X.size(0), input_dim_1, input_dim_1), dtype = torch.float).cuda()\n",
    "        \n",
    "    A_view = A.view(A.size(0), -1)\n",
    "    x_size = X.size(-1)\n",
    "    indices = X.narrow(-1, 0, x_size - 1) * A.stride(1) * A.stride(2) + X.narrow(-1, 1, x_size - 1) * A.stride(2)\n",
    "    A_view.scatter_(1, indices, 1)\n",
    "        \n",
    "    A_hat = A + torch.eye(input_dim_1, dtype = torch.float).cuda()\n",
    "    D_hat = A_hat.sum(dim = 1).pow(-1.0).diag_embed()\n",
    "    \n",
    "    return A_hat, D_hat\n",
    "\n",
    "def to_one_hot(X, input_dim_1):\n",
    "    \n",
    "    X = F.one_hot(X, num_classes = input_dim_1).float()    \n",
    "    X = X.permute(0, 2, 1)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1_network(\n",
      "  (dgcnn): DGCNN_network()\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (fc): Linear(in_features=9517, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "Parameters: 12618\n"
     ]
    }
   ],
   "source": [
    "class DGCNN_network(nn.Module):\n",
    "    \n",
    "    def __init__(self, weight_dim_1, weight_dim_2):\n",
    "\n",
    "        super(DGCNN_network, self).__init__()\n",
    "        self.weight_dim_1 = weight_dim_1\n",
    "        self.weight_dim_2 = weight_dim_2\n",
    "        self.weights = nn.Parameter(torch.rand((self.weight_dim_1, weight_dim_2), \n",
    "                                    dtype = torch.float, requires_grad = True))\n",
    "        \n",
    "    def forward(self, A_hat, D_hat, X):\n",
    "        return D_hat.matmul(A_hat).matmul(X).matmul(self.weights)\n",
    "\n",
    "class Model_1_network(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim_1, input_dim_2, weight_dim_2, dropout_rate):\n",
    "        \n",
    "        super(Model_1_network, self).__init__()\n",
    "        \n",
    "        self.input_dim_1 = input_dim_1\n",
    "        self.input_dim_2 = input_dim_2\n",
    "        self.weight_dim_1 = input_dim_2\n",
    "        self.weight_dim_2 = weight_dim_2\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.dgcnn = DGCNN_network(self.weight_dim_1, self.weight_dim_2)\n",
    "        self.dropout = nn.Dropout(p = self.dropout_rate)\n",
    "        self.fc = nn.Linear(self.input_dim_1 * self.weight_dim_2, 1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        A_hat, D_hat = norn_adj(X, input_dim_1)\n",
    "        X = to_one_hot(X, input_dim_1)        \n",
    "\n",
    "        H = self.dgcnn(A_hat, D_hat, X)\n",
    "        H = self.dropout(H)\n",
    "        H = torch.relu(H)\n",
    "        H = H.view(H.size(0), -1)\n",
    "        H = self.fc(H)\n",
    "        return H.squeeze()\n",
    "    \n",
    "model = Model_1_network(\n",
    "    input_dim_1 = 307,\n",
    "    input_dim_2 = 100,\n",
    "    weight_dim_2 = 31,\n",
    "    dropout_rate = 0.4\n",
    ")\n",
    "\n",
    "print(model)\n",
    "print(f'\\nParameters: {np.sum([param.numel() for param in model.parameters()])}')\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Convolutional Network using [DGL](https://docs.dgl.ai/en/latest/tutorials/models/1_gnn/1_gcn.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, the GCN model follows this formula:\n",
    "\n",
    "$H^{(l+1)} = \\sigma(\\tilde{D}^{-\\frac{1}{2}}\\tilde{A}\\tilde{D}^{-\\frac{1}{2}}H^{(l)}W^{(l)})$\n",
    "\n",
    "Here, $H^{(l)}$ denotes the $l^{th}$ layer in the network,\n",
    "$\\sigma$ is the non-linearity, and $W$ is the weight matrix for\n",
    "this layer. $D$ and $A$, as commonly seen, represent degree\n",
    "matrix and adjacency matrix, respectively. The ~ is a renormalization trick\n",
    "in which we add a self-connection to each node of the graph, and build the\n",
    "corresponding degree and adjacency matrix.  The shape of the input\n",
    "$H^{(0)}$ is $N \\times D$, where $N$ is the number of nodes\n",
    "and $D$ is the number of input features. We can chain up multiple\n",
    "layers as such to produce a node-level representation output with shape\n",
    ":math`N \\times F`, where $F$ is the dimension of the output node\n",
    "feature vector.\n",
    "\n",
    "The equation can be efficiently implemented using sparse matrix\n",
    "multiplication kernels (such as Kipf's\n",
    "`pygcn <https://github.com/tkipf/pygcn>`_ code). The above DGL implementation\n",
    "in fact has already used this trick due to the use of builtin functions. To\n",
    "understand what is under the hood, please read our tutorial on :doc:`PageRank <../../basics/3_pagerank>`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "\n",
    "gcn_msg = fn.copy_src(src='h', out='m')\n",
    "gcn_reduce = fn.sum(msg='m', out='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeApplyModule(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(NodeApplyModule, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, node):\n",
    "        h = self.linear(node.data['h'])\n",
    "        if self.activation is not None:\n",
    "            h = self.activation(h)\n",
    "        return {'h' : h}\n",
    "    \n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(GCN, self).__init__()\n",
    "        self.apply_mod = NodeApplyModule(in_feats, out_feats, activation)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        g.ndata['h'] = feature\n",
    "        g.update_all(gcn_msg, gcn_reduce)\n",
    "        g.apply_nodes(func=self.apply_mod)\n",
    "        return g.ndata.pop('h')\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.gcn1 = GCN(1433, 16, F.relu)\n",
    "        self.gcn2 = GCN(16, 7, None)\n",
    "    \n",
    "    def forward(self, g, features):\n",
    "        x = self.gcn1(g, features)\n",
    "        x = self.gcn2(g, x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (gcn1): GCN(\n",
      "    (apply_mod): NodeApplyModule(\n",
      "      (linear): Linear(in_features=1433, out_features=16, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (gcn2): GCN(\n",
      "    (apply_mod): NodeApplyModule(\n",
      "      (linear): Linear(in_features=16, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import citation_graph as citegrh\n",
    "import networkx as nx\n",
    "def load_cora_data():\n",
    "    data = citegrh.load_cora()\n",
    "    features = torch.FloatTensor(data.features)\n",
    "    labels = torch.LongTensor(data.labels)\n",
    "    train_mask = torch.ByteTensor(data.train_mask)\n",
    "    test_mask = torch.ByteTensor(data.test_mask)\n",
    "    g = data.graph\n",
    "    # add self loop\n",
    "    g.remove_edges_from(nx.selfloop_edges(g))\n",
    "    g = DGLGraph(g)\n",
    "    g.add_edges(g.nodes(), g.nodes())\n",
    "    return g, features, labels, train_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, g, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(g, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /Users/Pablo/.dgl/cora.zip from https://s3.us-east-2.amazonaws.com/dgl.ai/dataset/cora_raw.zip...\n",
      "Extracting file to /Users/Pablo/.dgl/cora\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pablo/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/Pablo/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 1.9488 | Test Acc 0.1300 | Time(s) nan\n",
      "Epoch 00001 | Loss 1.9159 | Test Acc 0.2160 | Time(s) nan\n",
      "Epoch 00002 | Loss 1.8868 | Test Acc 0.3250 | Time(s) nan\n",
      "Epoch 00003 | Loss 1.8604 | Test Acc 0.3740 | Time(s) 0.0239\n",
      "Epoch 00004 | Loss 1.8346 | Test Acc 0.3920 | Time(s) 0.0240\n",
      "Epoch 00005 | Loss 1.8087 | Test Acc 0.4040 | Time(s) 0.0252\n",
      "Epoch 00006 | Loss 1.7826 | Test Acc 0.4120 | Time(s) 0.0287\n",
      "Epoch 00007 | Loss 1.7562 | Test Acc 0.4230 | Time(s) 0.0280\n",
      "Epoch 00008 | Loss 1.7292 | Test Acc 0.4320 | Time(s) 0.0285\n",
      "Epoch 00009 | Loss 1.7017 | Test Acc 0.4380 | Time(s) 0.0280\n",
      "Epoch 00010 | Loss 1.6741 | Test Acc 0.4420 | Time(s) 0.0285\n",
      "Epoch 00011 | Loss 1.6465 | Test Acc 0.4440 | Time(s) 0.0287\n",
      "Epoch 00012 | Loss 1.6187 | Test Acc 0.4550 | Time(s) 0.0283\n",
      "Epoch 00013 | Loss 1.5910 | Test Acc 0.4620 | Time(s) 0.0279\n",
      "Epoch 00014 | Loss 1.5635 | Test Acc 0.4710 | Time(s) 0.0278\n",
      "Epoch 00015 | Loss 1.5363 | Test Acc 0.4810 | Time(s) 0.0280\n",
      "Epoch 00016 | Loss 1.5102 | Test Acc 0.4910 | Time(s) 0.0278\n",
      "Epoch 00017 | Loss 1.4846 | Test Acc 0.5020 | Time(s) 0.0275\n",
      "Epoch 00018 | Loss 1.4595 | Test Acc 0.5130 | Time(s) 0.0273\n",
      "Epoch 00019 | Loss 1.4348 | Test Acc 0.5290 | Time(s) 0.0270\n",
      "Epoch 00020 | Loss 1.4105 | Test Acc 0.5500 | Time(s) 0.0273\n",
      "Epoch 00021 | Loss 1.3864 | Test Acc 0.5580 | Time(s) 0.0272\n",
      "Epoch 00022 | Loss 1.3628 | Test Acc 0.5720 | Time(s) 0.0271\n",
      "Epoch 00023 | Loss 1.3399 | Test Acc 0.5820 | Time(s) 0.0270\n",
      "Epoch 00024 | Loss 1.3175 | Test Acc 0.5970 | Time(s) 0.0270\n",
      "Epoch 00025 | Loss 1.2959 | Test Acc 0.6110 | Time(s) 0.0272\n",
      "Epoch 00026 | Loss 1.2745 | Test Acc 0.6180 | Time(s) 0.0271\n",
      "Epoch 00027 | Loss 1.2535 | Test Acc 0.6270 | Time(s) 0.0270\n",
      "Epoch 00028 | Loss 1.2330 | Test Acc 0.6290 | Time(s) 0.0270\n",
      "Epoch 00029 | Loss 1.2130 | Test Acc 0.6380 | Time(s) 0.0270\n",
      "Epoch 00030 | Loss 1.1936 | Test Acc 0.6460 | Time(s) 0.0282\n",
      "Epoch 00031 | Loss 1.1750 | Test Acc 0.6490 | Time(s) 0.0286\n",
      "Epoch 00032 | Loss 1.1569 | Test Acc 0.6580 | Time(s) 0.0285\n",
      "Epoch 00033 | Loss 1.1393 | Test Acc 0.6610 | Time(s) 0.0287\n",
      "Epoch 00034 | Loss 1.1223 | Test Acc 0.6680 | Time(s) 0.0287\n",
      "Epoch 00035 | Loss 1.1059 | Test Acc 0.6720 | Time(s) 0.0286\n",
      "Epoch 00036 | Loss 1.0899 | Test Acc 0.6810 | Time(s) 0.0285\n",
      "Epoch 00037 | Loss 1.0743 | Test Acc 0.6880 | Time(s) 0.0285\n",
      "Epoch 00038 | Loss 1.0591 | Test Acc 0.6910 | Time(s) 0.0285\n",
      "Epoch 00039 | Loss 1.0443 | Test Acc 0.6950 | Time(s) 0.0284\n",
      "Epoch 00040 | Loss 1.0298 | Test Acc 0.7000 | Time(s) 0.0283\n",
      "Epoch 00041 | Loss 1.0157 | Test Acc 0.7030 | Time(s) 0.0282\n",
      "Epoch 00042 | Loss 1.0019 | Test Acc 0.7090 | Time(s) 0.0282\n",
      "Epoch 00043 | Loss 0.9883 | Test Acc 0.7130 | Time(s) 0.0283\n",
      "Epoch 00044 | Loss 0.9751 | Test Acc 0.7150 | Time(s) 0.0283\n",
      "Epoch 00045 | Loss 0.9622 | Test Acc 0.7180 | Time(s) 0.0282\n",
      "Epoch 00046 | Loss 0.9496 | Test Acc 0.7180 | Time(s) 0.0282\n",
      "Epoch 00047 | Loss 0.9373 | Test Acc 0.7180 | Time(s) 0.0284\n",
      "Epoch 00048 | Loss 0.9252 | Test Acc 0.7200 | Time(s) 0.0285\n",
      "Epoch 00049 | Loss 0.9134 | Test Acc 0.7230 | Time(s) 0.0284\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "g, features, labels, train_mask, test_mask = load_cora_data()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "dur = []\n",
    "for epoch in range(50):\n",
    "    if epoch >=3:\n",
    "        t0 = time.time()\n",
    "\n",
    "    net.train()\n",
    "    logits = net(g, features)\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    loss = F.nll_loss(logp[train_mask], labels[train_mask])\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch >=3:\n",
    "        dur.append(time.time() - t0)\n",
    "    \n",
    "    acc = evaluate(net, g, features, labels, test_mask)\n",
    "    print(\"Epoch {:05d} | Loss {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}\".format(\n",
    "            epoch, loss.item(), acc, np.mean(dur)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Convolutional Network using [PyTorch Geometric](https://github.com/rusty1s/pytorch_geometric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
